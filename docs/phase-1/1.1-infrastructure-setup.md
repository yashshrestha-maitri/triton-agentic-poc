# Task 1.1: Infrastructure Setup

## Metadata

| Field | Value |
|-------|-------|
| **Phase** | Phase 1: Foundation & Infrastructure |
| **Sub-Phase** | 1.1 |
| **Priority** | ðŸ”´ P0 - Critical (Blocking) |
| **Estimated Effort** | 3 days (24 hours) |
| **Dependencies** | None (first task in project) |
| **Status** | ðŸŸ¡ In Progress |
| **Owner** | DevOps Engineer |
| **Reviewer** | Tech Lead |
| **Created** | 2025-12-17 |
| **Target Completion** | 2025-12-20 |

---

## Description

### Overview

This task establishes the foundational infrastructure for the entire Triton platform by setting up containerized services using Docker Compose. The infrastructure includes four core services that provide data storage, caching, messaging, and object storage capabilities.

All services must run in Docker containers with proper networking, health checks, and data persistence. This ensures consistent environments across development, staging, and production, eliminates "works on my machine" issues, and provides the foundation for all subsequent development phases.

### Why This is Critical

**Without this foundation:**
- No database to store clients, templates, or ROI models
- No analytics data warehouse for Clickhouse queries
- No message broker for real-time job updates
- No object storage for documents and files

**This task blocks:**
- Phase 1.2 (Database Schema) - needs PostgreSQL and Clickhouse running
- Phase 1.3 (Message Broker) - needs Redis running
- Phase 2 (Research Agents) - needs S3 for document storage
- All subsequent phases depend on this infrastructure

### Technical Context

The infrastructure uses Docker Compose to orchestrate four services:
1. **PostgreSQL**: Relational database for structured data (clients, templates, ROI models)
2. **Clickhouse**: Columnar database for analytics (claims data, 100M+ rows)
3. **Redis**: In-memory data store for caching and pub/sub messaging
4. **LocalStack/S3**: Object storage for documents, ROI stories, and generated files

All services run in isolated containers but communicate via a shared Docker network. Health checks ensure services are ready before dependent services start. Volume mounts persist data across container restarts.

---

## Objectives

### Primary Objectives

1. âœ… **Create Docker Compose Configuration**
   - Define all four services (PostgreSQL, Clickhouse, Redis, S3)
   - Configure service dependencies and startup order
   - Set environment variables for each service
   - Define volume mounts for data persistence

2. âœ… **Configure Service Networking**
   - Create custom Docker network (triton-network)
   - Assign static IPs or use service discovery
   - Enable inter-service communication
   - Expose necessary ports to host machine

3. âœ… **Implement Health Checks**
   - PostgreSQL: `pg_isready` command
   - Clickhouse: HTTP `/ping` endpoint
   - Redis: `redis-cli PING` command
   - LocalStack: HTTP health endpoint

4. âœ… **Set Up Data Persistence**
   - PostgreSQL: Volume for `/var/lib/postgresql/data`
   - Clickhouse: Volume for `/var/lib/clickhouse`
   - Redis: Volume for `/data`
   - LocalStack: Volume for `/tmp/localstack`

### Secondary Objectives

- Create development convenience scripts (start.sh, stop.sh, reset.sh)
- Document service connection strings
- Set up .env.example for configuration
- Create troubleshooting guide

---

## Tasks Breakdown

### Task 1: Create Docker Compose File
**Description**: Write docker-compose.yml defining all services
**Owner**: DevOps Engineer
**Estimated Effort**: 4 hours

**Steps:**
1. Create `docker-compose.yml` in project root
2. Define PostgreSQL service:
   - Image: `postgres:14-alpine`
   - Port: 5432
   - Environment: POSTGRES_USER, POSTGRES_PASSWORD, POSTGRES_DB
   - Volume: `postgres_data:/var/lib/postgresql/data`
   - Health check: `pg_isready -U triton_user`
3. Define Clickhouse service:
   - Image: `clickhouse/clickhouse-server:latest`
   - Ports: 9000 (native), 8123 (HTTP)
   - Volume: `clickhouse_data:/var/lib/clickhouse`
   - Health check: `curl -f http://localhost:8123/ping`
4. Define Redis service:
   - Image: `redis:7-alpine`
   - Port: 6379
   - Volume: `redis_data:/data`
   - Health check: `redis-cli ping`
5. Define LocalStack service (S3 emulation):
   - Image: `localstack/localstack:latest`
   - Port: 4566
   - Environment: SERVICES=s3
   - Volume: `localstack_data:/tmp/localstack`
   - Health check: `curl -f http://localhost:4566/_localstack/health`
6. Define custom network: `triton-network`
7. Define named volumes for data persistence

**Acceptance Criteria:**
- âœ… File validates with `docker-compose config`
- âœ… All services defined with correct images
- âœ… All ports exposed correctly
- âœ… All volumes defined

---

### Task 2: Configure Service Environment Variables
**Description**: Create .env.example with all configuration parameters
**Owner**: DevOps Engineer
**Estimated Effort**: 2 hours

**Steps:**
1. Create `.env.example` file in project root
2. Add PostgreSQL configuration:
   ```
   POSTGRES_USER=triton_user
   POSTGRES_PASSWORD=development_password_change_in_prod
   POSTGRES_DB=triton
   POSTGRES_PORT=5432
   DATABASE_URL=postgresql://triton_user:password@localhost:5432/triton
   ```
3. Add Clickhouse configuration:
   ```
   CLICKHOUSE_HOST=localhost
   CLICKHOUSE_PORT=9000
   CLICKHOUSE_HTTP_PORT=8123
   CLICKHOUSE_USER=default
   CLICKHOUSE_PASSWORD=
   ```
4. Add Redis configuration:
   ```
   REDIS_URL=redis://localhost:6379/0
   REDIS_PORT=6379
   ```
5. Add S3/LocalStack configuration:
   ```
   AWS_ENDPOINT_URL=http://localhost:4566
   AWS_ACCESS_KEY_ID=test
   AWS_SECRET_ACCESS_KEY=test
   AWS_DEFAULT_REGION=us-east-1
   S3_BUCKET=triton-documents
   ```
6. Add general application settings:
   ```
   ENVIRONMENT=development
   LOG_LEVEL=INFO
   DEBUG_MODE=true
   API_HOST=0.0.0.0
   API_PORT=8000
   ```

**Acceptance Criteria:**
- âœ… All required environment variables documented
- âœ… Default values provided for development
- âœ… Security note added for production passwords
- âœ… Variables grouped by service

---

### Task 3: Implement Health Checks
**Description**: Add health check commands to each service
**Owner**: DevOps Engineer
**Estimated Effort**: 3 hours

**Steps:**
1. **PostgreSQL Health Check:**
   - Command: `pg_isready -U triton_user -d triton`
   - Interval: 10 seconds
   - Timeout: 5 seconds
   - Retries: 5
   - Start period: 30 seconds
2. **Clickhouse Health Check:**
   - Command: `curl -f http://localhost:8123/ping || exit 1`
   - Interval: 10 seconds
   - Timeout: 5 seconds
   - Retries: 5
   - Start period: 40 seconds (Clickhouse takes longer to start)
3. **Redis Health Check:**
   - Command: `redis-cli ping | grep PONG`
   - Interval: 5 seconds
   - Timeout: 3 seconds
   - Retries: 3
   - Start period: 10 seconds
4. **LocalStack Health Check:**
   - Command: `curl -f http://localhost:4566/_localstack/health || exit 1`
   - Interval: 10 seconds
   - Timeout: 5 seconds
   - Retries: 5
   - Start period: 20 seconds
5. Test health checks:
   - Start services: `docker-compose up -d`
   - Check status: `docker-compose ps`
   - Verify all show "healthy" status within expected time

**Acceptance Criteria:**
- âœ… All services have health checks defined
- âœ… Health checks succeed when service is ready
- âœ… Health checks fail when service is down
- âœ… Start periods prevent false failures during initialization

---

### Task 4: Set Up Data Persistence
**Description**: Configure Docker volumes for data persistence
**Owner**: DevOps Engineer
**Estimated Effort**: 2 hours

**Steps:**
1. Define named volumes in docker-compose.yml:
   ```yaml
   volumes:
     postgres_data:
       driver: local
     clickhouse_data:
       driver: local
     redis_data:
       driver: local
     localstack_data:
       driver: local
   ```
2. Mount volumes to service containers:
   - PostgreSQL: `/var/lib/postgresql/data`
   - Clickhouse: `/var/lib/clickhouse` and `/var/log/clickhouse-server`
   - Redis: `/data`
   - LocalStack: `/tmp/localstack`
3. Test data persistence:
   - Start services and create test data
   - Stop containers: `docker-compose down`
   - Restart containers: `docker-compose up -d`
   - Verify data still exists

**Acceptance Criteria:**
- âœ… Data persists after container restart
- âœ… Volumes created automatically on first start
- âœ… Volume sizes are reasonable (< 10GB initially)
- âœ… Volume locations documented

---

### Task 5: Configure Service Dependencies
**Description**: Define startup order and dependencies between services
**Owner**: DevOps Engineer
**Estimated Effort**: 2 hours

**Steps:**
1. Add `depends_on` with health condition checks:
   - FastAPI app (added in 1.4) depends on:
     - PostgreSQL (healthy)
     - Redis (healthy)
     - Clickhouse (healthy)
2. Document startup sequence:
   - PostgreSQL starts first (no dependencies)
   - Clickhouse starts first (no dependencies)
   - Redis starts first (no dependencies)
   - LocalStack starts first (no dependencies)
   - Application waits for all infrastructure (Phase 1.4)
3. Test startup order:
   - Stop all: `docker-compose down`
   - Start all: `docker-compose up`
   - Verify services start in correct order
   - Verify dependent services wait for dependencies

**Acceptance Criteria:**
- âœ… Services start in correct order
- âœ… Dependent services wait for health checks
- âœ… No connection errors during startup
- âœ… Startup completes within 60 seconds

---

### Task 6: Create Convenience Scripts
**Description**: Create bash scripts for common operations
**Owner**: DevOps Engineer
**Estimated Effort**: 2 hours

**Steps:**
1. Create `scripts/start-infrastructure.sh`:
   - Starts all infrastructure services
   - Waits for health checks
   - Prints connection strings
2. Create `scripts/stop-infrastructure.sh`:
   - Gracefully stops all services
   - Preserves data (no volume removal)
3. Create `scripts/reset-infrastructure.sh`:
   - Stops all services
   - Removes volumes (data loss warning)
   - Recreates clean environment
4. Create `scripts/check-infrastructure.sh`:
   - Checks health of all services
   - Prints status summary
   - Returns exit code 0 if all healthy
5. Make all scripts executable: `chmod +x scripts/*.sh`
6. Test all scripts

**Acceptance Criteria:**
- âœ… All scripts execute without errors
- âœ… Scripts provide clear output
- âœ… Error messages are helpful
- âœ… Scripts handle edge cases (already running, not running, etc.)

---

### Task 7: Integration Testing
**Description**: Verify all services work together
**Owner**: QA Engineer
**Estimated Effort**: 4 hours

**Steps:**
1. **Clean Start Test:**
   - Remove all containers and volumes
   - Run `docker-compose up -d`
   - Verify all services become healthy
   - Check logs for errors
2. **Connection Test:**
   - PostgreSQL: `psql -h localhost -U triton_user -d triton -c "SELECT 1;"`
   - Clickhouse: `curl http://localhost:8123/ping`
   - Redis: `redis-cli ping`
   - LocalStack: `aws --endpoint-url=http://localhost:4566 s3 ls`
3. **Data Persistence Test:**
   - Create test data in each service
   - Stop containers
   - Start containers
   - Verify data persists
4. **Failure Recovery Test:**
   - Stop one service
   - Verify others continue running
   - Restart stopped service
   - Verify it recovers correctly
5. **Resource Usage Test:**
   - Monitor CPU usage: `docker stats`
   - Monitor memory usage
   - Verify no memory leaks (run for 1 hour)

**Acceptance Criteria:**
- âœ… All services start successfully
- âœ… All services pass connection tests
- âœ… Data persists across restarts
- âœ… Services recover from failures
- âœ… Resource usage is reasonable (< 4GB RAM total)

---

### Task 8: Documentation
**Description**: Document infrastructure setup and troubleshooting
**Owner**: DevOps Engineer
**Estimated Effort**: 3 hours

**Steps:**
1. Create `docs/phase-1/INFRASTRUCTURE_TROUBLESHOOTING.md`:
   - Common issues and solutions
   - Port conflict resolution
   - Volume permission issues
   - Health check failures
2. Update README.md with quick start instructions
3. Document service connection strings
4. Create architecture diagram (ASCII art)
5. Document backup and restore procedures

**Acceptance Criteria:**
- âœ… Documentation covers all common issues
- âœ… Quick start guide works for new developers
- âœ… Connection strings documented
- âœ… Troubleshooting guide tested

---

## Acceptance Criteria

### Must-Have (Blocking)

âœ… **Service Startup:**
- [ ] `docker-compose up -d` starts all services without errors
- [ ] All services show "healthy" status within 60 seconds
- [ ] No error messages in logs during startup

âœ… **Health Checks:**
- [ ] PostgreSQL health check passes: `docker-compose ps | grep postgres | grep healthy`
- [ ] Clickhouse health check passes: `docker-compose ps | grep clickhouse | grep healthy`
- [ ] Redis health check passes: `docker-compose ps | grep redis | grep healthy`
- [ ] LocalStack health check passes: `docker-compose ps | grep localstack | grep healthy`

âœ… **Service Connectivity:**
- [ ] PostgreSQL accepts connections: `psql -h localhost -U triton_user -d triton -c "SELECT 1;"`
- [ ] Clickhouse accepts connections: `curl http://localhost:8123/ping` returns "Ok."
- [ ] Redis accepts connections: `redis-cli ping` returns "PONG"
- [ ] LocalStack accepts connections: `aws --endpoint-url=http://localhost:4566 s3 ls` succeeds

âœ… **Data Persistence:**
- [ ] PostgreSQL data persists after restart
- [ ] Clickhouse data persists after restart
- [ ] Redis data persists after restart
- [ ] LocalStack data persists after restart

âœ… **Configuration:**
- [ ] `.env.example` file exists with all variables
- [ ] `docker-compose.yml` validates: `docker-compose config`
- [ ] All services use environment variables correctly

âœ… **Documentation:**
- [ ] Quick start guide in README.md
- [ ] Connection strings documented
- [ ] Troubleshooting guide created

### Nice-to-Have (Optional)

- [ ] Monitoring dashboards for resource usage
- [ ] Automated backup scripts
- [ ] CI/CD integration for infrastructure tests
- [ ] Performance benchmarks documented

---

## Workflow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  INFRASTRUCTURE SETUP WORKFLOW                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

START
  â”‚
  â”œâ”€ Day 1: Docker Compose Configuration (4 hours)
  â”‚   â”‚
  â”‚   â”œâ”€ Define PostgreSQL Service
  â”‚   â”‚   â”œâ”€ Image: postgres:14-alpine
  â”‚   â”‚   â”œâ”€ Port: 5432
  â”‚   â”‚   â”œâ”€ Environment: USER, PASSWORD, DB
  â”‚   â”‚   â”œâ”€ Volume: postgres_data â†’ /var/lib/postgresql/data
  â”‚   â”‚   â””â”€ Health Check: pg_isready -U triton_user
  â”‚   â”‚
  â”‚   â”œâ”€ Define Clickhouse Service
  â”‚   â”‚   â”œâ”€ Image: clickhouse/clickhouse-server:latest
  â”‚   â”‚   â”œâ”€ Ports: 9000 (native), 8123 (HTTP)
  â”‚   â”‚   â”œâ”€ Volume: clickhouse_data â†’ /var/lib/clickhouse
  â”‚   â”‚   â””â”€ Health Check: curl http://localhost:8123/ping
  â”‚   â”‚
  â”‚   â”œâ”€ Define Redis Service
  â”‚   â”‚   â”œâ”€ Image: redis:7-alpine
  â”‚   â”‚   â”œâ”€ Port: 6379
  â”‚   â”‚   â”œâ”€ Volume: redis_data â†’ /data
  â”‚   â”‚   â””â”€ Health Check: redis-cli ping
  â”‚   â”‚
  â”‚   â”œâ”€ Define LocalStack Service
  â”‚   â”‚   â”œâ”€ Image: localstack/localstack:latest
  â”‚   â”‚   â”œâ”€ Port: 4566
  â”‚   â”‚   â”œâ”€ Environment: SERVICES=s3
  â”‚   â”‚   â”œâ”€ Volume: localstack_data â†’ /tmp/localstack
  â”‚   â”‚   â””â”€ Health Check: curl localhost:4566/_localstack/health
  â”‚   â”‚
  â”‚   â”œâ”€ Create Custom Network
  â”‚   â”‚   â””â”€ triton-network (bridge driver)
  â”‚   â”‚
  â”‚   â””â”€ Define Named Volumes
  â”‚       â”œâ”€ postgres_data
  â”‚       â”œâ”€ clickhouse_data
  â”‚       â”œâ”€ redis_data
  â”‚       â””â”€ localstack_data
  â”‚
  â”œâ”€ Day 1: Environment Configuration (2 hours)
  â”‚   â”‚
  â”‚   â”œâ”€ Create .env.example
  â”‚   â”‚   â”œâ”€ PostgreSQL variables
  â”‚   â”‚   â”œâ”€ Clickhouse variables
  â”‚   â”‚   â”œâ”€ Redis variables
  â”‚   â”‚   â”œâ”€ S3/LocalStack variables
  â”‚   â”‚   â””â”€ Application variables
  â”‚   â”‚
  â”‚   â””â”€ Validate Configuration
  â”‚       â””â”€ docker-compose config âœ…
  â”‚
  â”œâ”€ Day 2: Health Checks Implementation (3 hours)
  â”‚   â”‚
  â”‚   â”œâ”€ Add PostgreSQL Health Check
  â”‚   â”‚   â”œâ”€ Command: pg_isready -U triton_user -d triton
  â”‚   â”‚   â”œâ”€ Interval: 10s, Timeout: 5s, Retries: 5
  â”‚   â”‚   â””â”€ Start Period: 30s
  â”‚   â”‚
  â”‚   â”œâ”€ Add Clickhouse Health Check
  â”‚   â”‚   â”œâ”€ Command: curl -f http://localhost:8123/ping
  â”‚   â”‚   â”œâ”€ Interval: 10s, Timeout: 5s, Retries: 5
  â”‚   â”‚   â””â”€ Start Period: 40s
  â”‚   â”‚
  â”‚   â”œâ”€ Add Redis Health Check
  â”‚   â”‚   â”œâ”€ Command: redis-cli ping | grep PONG
  â”‚   â”‚   â”œâ”€ Interval: 5s, Timeout: 3s, Retries: 3
  â”‚   â”‚   â””â”€ Start Period: 10s
  â”‚   â”‚
  â”‚   â””â”€ Add LocalStack Health Check
  â”‚       â”œâ”€ Command: curl -f localhost:4566/_localstack/health
  â”‚       â”œâ”€ Interval: 10s, Timeout: 5s, Retries: 5
  â”‚       â””â”€ Start Period: 20s
  â”‚
  â”œâ”€ Day 2: Data Persistence Setup (2 hours)
  â”‚   â”‚
  â”‚   â”œâ”€ Mount Volumes to Containers
  â”‚   â”‚   â”œâ”€ PostgreSQL: /var/lib/postgresql/data
  â”‚   â”‚   â”œâ”€ Clickhouse: /var/lib/clickhouse
  â”‚   â”‚   â”œâ”€ Redis: /data
  â”‚   â”‚   â””â”€ LocalStack: /tmp/localstack
  â”‚   â”‚
  â”‚   â””â”€ Test Persistence
  â”‚       â”œâ”€ Create test data
  â”‚       â”œâ”€ Stop containers: docker-compose down
  â”‚       â”œâ”€ Start containers: docker-compose up -d
  â”‚       â””â”€ Verify data exists âœ…
  â”‚
  â”œâ”€ Day 2: Service Dependencies (2 hours)
  â”‚   â”‚
  â”‚   â”œâ”€ Define Startup Order
  â”‚   â”‚   â”œâ”€ PostgreSQL (no dependencies)
  â”‚   â”‚   â”œâ”€ Clickhouse (no dependencies)
  â”‚   â”‚   â”œâ”€ Redis (no dependencies)
  â”‚   â”‚   â””â”€ LocalStack (no dependencies)
  â”‚   â”‚
  â”‚   â””â”€ Test Startup Order
  â”‚       â”œâ”€ docker-compose down
  â”‚       â”œâ”€ docker-compose up
  â”‚       â””â”€ Verify correct order âœ…
  â”‚
  â”œâ”€ Day 3: Convenience Scripts (2 hours)
  â”‚   â”‚
  â”‚   â”œâ”€ Create start-infrastructure.sh
  â”‚   â”‚   â”œâ”€ docker-compose up -d
  â”‚   â”‚   â”œâ”€ Wait for health checks
  â”‚   â”‚   â””â”€ Print connection strings
  â”‚   â”‚
  â”‚   â”œâ”€ Create stop-infrastructure.sh
  â”‚   â”‚   â””â”€ docker-compose down (preserves data)
  â”‚   â”‚
  â”‚   â”œâ”€ Create reset-infrastructure.sh
  â”‚   â”‚   â”œâ”€ docker-compose down -v (removes data)
  â”‚   â”‚   â””â”€ Warning prompt
  â”‚   â”‚
  â”‚   â”œâ”€ Create check-infrastructure.sh
  â”‚   â”‚   â”œâ”€ Check health of all services
  â”‚   â”‚   â”œâ”€ Print status summary
  â”‚   â”‚   â””â”€ Exit 0 if all healthy
  â”‚   â”‚
  â”‚   â””â”€ Make Scripts Executable
  â”‚       â””â”€ chmod +x scripts/*.sh
  â”‚
  â”œâ”€ Day 3: Integration Testing (4 hours)
  â”‚   â”‚
  â”‚   â”œâ”€ Clean Start Test
  â”‚   â”‚   â”œâ”€ Remove all containers & volumes
  â”‚   â”‚   â”œâ”€ docker-compose up -d
  â”‚   â”‚   â””â”€ Verify all healthy âœ…
  â”‚   â”‚
  â”‚   â”œâ”€ Connection Test
  â”‚   â”‚   â”œâ”€ Test PostgreSQL connection
  â”‚   â”‚   â”œâ”€ Test Clickhouse connection
  â”‚   â”‚   â”œâ”€ Test Redis connection
  â”‚   â”‚   â””â”€ Test LocalStack connection âœ…
  â”‚   â”‚
  â”‚   â”œâ”€ Data Persistence Test
  â”‚   â”‚   â”œâ”€ Create data in all services
  â”‚   â”‚   â”œâ”€ Restart containers
  â”‚   â”‚   â””â”€ Verify data persists âœ…
  â”‚   â”‚
  â”‚   â”œâ”€ Failure Recovery Test
  â”‚   â”‚   â”œâ”€ Stop one service
  â”‚   â”‚   â”œâ”€ Verify others continue
  â”‚   â”‚   â””â”€ Restart and verify recovery âœ…
  â”‚   â”‚
  â”‚   â””â”€ Resource Usage Test
  â”‚       â”œâ”€ Monitor CPU: docker stats
  â”‚       â”œâ”€ Monitor memory usage
  â”‚       â””â”€ Verify < 4GB RAM total âœ…
  â”‚
  â””â”€ Day 3: Documentation (3 hours)
      â”‚
      â”œâ”€ Create Troubleshooting Guide
      â”‚   â”œâ”€ Port conflicts
      â”‚   â”œâ”€ Permission issues
      â”‚   â””â”€ Health check failures
      â”‚
      â”œâ”€ Update README.md
      â”‚   â”œâ”€ Quick start instructions
      â”‚   â””â”€ Connection strings
      â”‚
      â””â”€ Create Architecture Diagram
          â””â”€ ASCII art showing all services

END: Infrastructure Ready âœ…

OUTPUT:
â”œâ”€ All services running in Docker
â”œâ”€ Health checks passing
â”œâ”€ Data persisting across restarts
â”œâ”€ Scripts for common operations
â””â”€ Documentation complete

READY FOR: Phase 1.2 (Database Schema Design)
```

---

## Technical Requirements

### Software Requirements

| Software | Minimum Version | Purpose |
|----------|----------------|---------|
| Docker | 20.10+ | Container runtime |
| Docker Compose | 2.0+ | Multi-container orchestration |
| Bash | 4.0+ | Shell scripts |

### System Requirements

| Resource | Minimum | Recommended |
|----------|---------|-------------|
| RAM | 4GB free | 8GB free |
| Disk Space | 10GB free | 20GB free |
| CPU Cores | 2 | 4 |
| Network | 10 Mbps | 100 Mbps |

### Port Requirements

| Service | Port | Protocol | Must Be Free |
|---------|------|----------|--------------|
| PostgreSQL | 5432 | TCP | Yes |
| Clickhouse (native) | 9000 | TCP | Yes |
| Clickhouse (HTTP) | 8123 | HTTP | Yes |
| Redis | 6379 | TCP | Yes |
| LocalStack | 4566 | HTTP | Yes |
| API (Phase 1.4) | 8000 | HTTP | Yes |

### Docker Images

| Service | Image | Size | Pull Time (10 Mbps) |
|---------|-------|------|----------------------|
| PostgreSQL | postgres:14-alpine | ~80MB | ~1 min |
| Clickhouse | clickhouse/clickhouse-server:latest | ~500MB | ~7 min |
| Redis | redis:7-alpine | ~30MB | ~30 sec |
| LocalStack | localstack/localstack:latest | ~800MB | ~11 min |

**Total Download:** ~1.4GB (~20 minutes on 10 Mbps connection)

---

## Testing Strategy

### Unit Tests (N/A for Infrastructure)
Infrastructure setup is primarily configuration, so unit tests don't apply. Testing focuses on integration and validation.

### Integration Tests

**Test Suite: Infrastructure Health**
```bash
#!/bin/bash
# tests/test_infrastructure.sh

# Test 1: Services start successfully
docker-compose up -d
sleep 30  # Wait for services to initialize

# Test 2: All services are healthy
HEALTHY_COUNT=$(docker-compose ps | grep "healthy" | wc -l)
if [ "$HEALTHY_COUNT" != "4" ]; then
  echo "FAIL: Not all services are healthy"
  exit 1
fi

# Test 3: PostgreSQL connection
psql -h localhost -U triton_user -d triton -c "SELECT 1;" > /dev/null
if [ $? -ne 0 ]; then
  echo "FAIL: PostgreSQL connection failed"
  exit 1
fi

# Test 4: Clickhouse connection
RESPONSE=$(curl -s http://localhost:8123/ping)
if [ "$RESPONSE" != "Ok." ]; then
  echo "FAIL: Clickhouse connection failed"
  exit 1
fi

# Test 5: Redis connection
RESPONSE=$(redis-cli ping)
if [ "$RESPONSE" != "PONG" ]; then
  echo "FAIL: Redis connection failed"
  exit 1
fi

# Test 6: LocalStack connection
aws --endpoint-url=http://localhost:4566 s3 ls > /dev/null 2>&1
if [ $? -ne 0 ]; then
  echo "FAIL: LocalStack connection failed"
  exit 1
fi

echo "SUCCESS: All infrastructure tests passed"
exit 0
```

### Manual Testing Checklist

- [ ] Start from clean state: Remove all containers and volumes
- [ ] Run `docker-compose up -d`
- [ ] Verify all services show "healthy" within 60 seconds
- [ ] Test PostgreSQL: `psql -h localhost -U triton_user -d triton -c "SELECT 1;"`
- [ ] Test Clickhouse: `curl http://localhost:8123/ping`
- [ ] Test Redis: `redis-cli ping`
- [ ] Test LocalStack: `aws --endpoint-url=http://localhost:4566 s3 mb s3://test-bucket`
- [ ] Create test data in PostgreSQL
- [ ] Run `docker-compose down` (preserves data)
- [ ] Run `docker-compose up -d`
- [ ] Verify test data still exists
- [ ] Check logs for errors: `docker-compose logs`
- [ ] Check resource usage: `docker stats` (< 4GB RAM)

### Performance Testing

**Resource Usage Benchmarks:**
- PostgreSQL: < 200MB RAM idle, < 500MB under load
- Clickhouse: < 500MB RAM idle, < 2GB under load
- Redis: < 50MB RAM
- LocalStack: < 300MB RAM

**Startup Time:**
- Target: All services healthy within 60 seconds
- PostgreSQL: ~10 seconds
- Clickhouse: ~20 seconds
- Redis: ~5 seconds
- LocalStack: ~15 seconds

---

## Rollback Plan

### If Task Fails or Needs Rollback

**Scenario 1: Services won't start**
1. Check Docker daemon is running: `systemctl status docker`
2. Check port conflicts: `netstat -tuln | grep -E '5432|6379|9000|8123|4566'`
3. Review logs: `docker-compose logs`
4. Reset environment:
   ```bash
   docker-compose down -v
   docker system prune -f
   ```
5. Start fresh: `docker-compose up -d`

**Scenario 2: Data corruption**
1. Stop services: `docker-compose down`
2. Backup volumes (if possible):
   ```bash
   docker run --rm -v postgres_data:/data -v $(pwd):/backup alpine \
     tar czf /backup/postgres_backup.tar.gz /data
   ```
3. Remove corrupted volumes: `docker volume rm postgres_data`
4. Restart services: `docker-compose up -d`
5. Restore from backup (if available)

**Scenario 3: Performance issues**
1. Check resource usage: `docker stats`
2. Identify resource-heavy container
3. Adjust resource limits in docker-compose.yml:
   ```yaml
   deploy:
     resources:
       limits:
         cpus: '2.0'
         memory: 2G
   ```
4. Restart services: `docker-compose restart`

**Scenario 4: Need to start over completely**
```bash
# Nuclear option - removes everything
docker-compose down -v
docker system prune -a -f --volumes
# Restart from Task 1
```

### Rollback Checklist

- [ ] Stop all services: `docker-compose down`
- [ ] Backup data if needed (see Scenario 2)
- [ ] Document the issue and root cause
- [ ] Remove problematic changes
- [ ] Test rollback: Verify services start
- [ ] Update documentation with lessons learned

---

## Related Documentation

### Phase 1 Documentation
- [Phase 1 README](./README.md) - Phase overview
- [1.2 Database Schema Design](./1.2-database-schema.md) - Next task (depends on 1.1)
- [1.3 Message Broker Implementation](./1.3-message-broker-implementation.md) - Message broker setup
- [1.4 API Foundation](./1.4-api-foundation.md) - FastAPI setup

### Reference Documentation (Moved to Phase 1)
- [DOCKER_SETUP.md](./DOCKER_SETUP.md) - Detailed Docker deployment guide
- [FOUNDATION_AND_INFRASTRUCTURE.md](./FOUNDATION_AND_INFRASTRUCTURE.md) - Infrastructure deep dive

### External Resources
- [Docker Compose Documentation](https://docs.docker.com/compose/)
- [PostgreSQL Docker Hub](https://hub.docker.com/_/postgres)
- [Clickhouse Docker Image](https://hub.docker.com/r/clickhouse/clickhouse-server)
- [Redis Docker Hub](https://hub.docker.com/_/redis)
- [LocalStack Documentation](https://docs.localstack.cloud/)

### Troubleshooting Resources
- [Docker Troubleshooting Guide](https://docs.docker.com/config/daemon/)
- [PostgreSQL Connection Issues](https://www.postgresql.org/docs/current/server-start.html)
- [Clickhouse Troubleshooting](https://clickhouse.com/docs/en/operations/troubleshooting/)

---

## Notes & Comments

### Design Decisions

**Why Docker Compose instead of Kubernetes?**
- Simpler for development environment
- Lower resource overhead
- Easier for developers to run locally
- Production can use Kubernetes (Phase 6) with same images

**Why LocalStack instead of real S3?**
- No AWS costs during development
- Faster iteration (no network latency)
- Can test S3 operations offline
- Easy to reset state for testing

**Why named volumes instead of bind mounts?**
- Better cross-platform compatibility (Windows, Mac, Linux)
- Docker manages permissions
- Easier to backup and restore
- Better performance on non-Linux hosts

### Common Pitfalls

**Port Conflicts:**
- Problem: Port 5432 already in use by local PostgreSQL
- Solution: Stop local PostgreSQL or change port in docker-compose.yml

**Permission Issues:**
- Problem: Container can't write to volume
- Solution: Check volume ownership, use named volumes instead of bind mounts

**Health Check Failures:**
- Problem: Health check times out
- Solution: Increase start_period in docker-compose.yml

**Slow Startup:**
- Problem: Containers take > 2 minutes to become healthy
- Solution: Check disk I/O, increase resources, or use SSD

---

## Success Metrics

| Metric | Target | Measurement Method |
|--------|--------|--------------------|
| **Startup Time** | < 60 seconds | Time from `docker-compose up` to all services healthy |
| **Health Check Success Rate** | 100% | All services pass health checks on first try |
| **Data Persistence** | 100% | All data persists after restart |
| **Resource Usage (RAM)** | < 4GB | `docker stats` shows total memory usage |
| **Resource Usage (CPU)** | < 50% | `docker stats` shows CPU usage at idle |
| **Connection Success Rate** | 100% | All connection tests pass |
| **Uptime** | 99.9% | Services remain healthy during 1-hour test |

---

**Task Owner:** DevOps Engineer
**Last Updated:** 2025-12-17
**Next Review:** Daily during implementation

**Ready to Start?** Read [Phase 1 README](./README.md) first, then begin Task 1: Create Docker Compose File.
